{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/STAT 121A/AC 209A/CSCI E-109A: \n",
    "# Spotify Final Project: Group 31\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2017**<br/>\n",
    "**Group Members**: Michelle Chiang, David Seong, Emily Chen<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, Rahul Dave, Margo Levine\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilychen1/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import datetime as DT\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "import operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Predictors Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shotgun Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read csv of spotify predictors\n",
    "df = pd.read_csv('spotify_predictors.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop(['Unnamed: 0'], 1)\n",
    "df = pd.get_dummies(df, columns=['majority_album_type'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers</th>\n",
       "      <th>majority_artist_genres</th>\n",
       "      <th>name</th>\n",
       "      <th>owner</th>\n",
       "      <th>track_ids</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>avg_song_popularity</th>\n",
       "      <th>avg_loudness</th>\n",
       "      <th>avg_speechiness</th>\n",
       "      <th>avg_acousticness</th>\n",
       "      <th>avg_instrumentalness</th>\n",
       "      <th>avg_liveness</th>\n",
       "      <th>avg_valence</th>\n",
       "      <th>avg_num_artists</th>\n",
       "      <th>avg_num_markets</th>\n",
       "      <th>majority_explicit</th>\n",
       "      <th>majority_mode</th>\n",
       "      <th>avg_album_popularity</th>\n",
       "      <th>avg_album_release_year</th>\n",
       "      <th>avg_artist_popularity</th>\n",
       "      <th>avg_artist_followers</th>\n",
       "      <th>majority_album_type_album</th>\n",
       "      <th>majority_album_type_compilation</th>\n",
       "      <th>majority_album_type_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18129916</td>\n",
       "      <td>pop</td>\n",
       "      <td>Today's Top Hits</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['0tBbt8CrmxbjRP0pueQkyU', ' 2amzBJRBPOGszBem4...</td>\n",
       "      <td>50</td>\n",
       "      <td>84.277778</td>\n",
       "      <td>-5.696467</td>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.170962</td>\n",
       "      <td>2.145467e-05</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>0.326580</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.444444</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>91.160000</td>\n",
       "      <td>2.545533e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3787551</td>\n",
       "      <td>indie r&amp;b</td>\n",
       "      <td>Are &amp; Be</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['6gU9OKjOE7ghfEd55oRO57', ' 25wStx3LyTjYmHTd3...</td>\n",
       "      <td>51</td>\n",
       "      <td>62.090909</td>\n",
       "      <td>-8.381700</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>0.299180</td>\n",
       "      <td>7.865653e-02</td>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.306480</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>34.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.727273</td>\n",
       "      <td>2016.818182</td>\n",
       "      <td>75.200000</td>\n",
       "      <td>1.603455e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4254642</td>\n",
       "      <td>contemporary country</td>\n",
       "      <td>Hot Country</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['54EWDYWhs4w6SODnxabuoh', ' 7rdK9NSJIRBZAiXC0...</td>\n",
       "      <td>51</td>\n",
       "      <td>77.200000</td>\n",
       "      <td>-6.154000</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.199580</td>\n",
       "      <td>4.080000e-07</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>50.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.400000</td>\n",
       "      <td>2016.400000</td>\n",
       "      <td>78.857143</td>\n",
       "      <td>9.805109e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6639722</td>\n",
       "      <td>latin</td>\n",
       "      <td>Â¡Viva Latino!</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['2hl6q70unbviGo3g1R7uFx', ' 2SmgFAhQkQCQPyBiB...</td>\n",
       "      <td>50</td>\n",
       "      <td>83.222222</td>\n",
       "      <td>-4.502375</td>\n",
       "      <td>0.084313</td>\n",
       "      <td>0.151738</td>\n",
       "      <td>1.028625e-05</td>\n",
       "      <td>0.120575</td>\n",
       "      <td>0.614750</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>94.142857</td>\n",
       "      <td>2.632650e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3323766</td>\n",
       "      <td>focus</td>\n",
       "      <td>Peaceful Piano</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['1JoAjYaI3zvhXVx41HH7Fc', ' 7ih16mauHrpUMOIeW...</td>\n",
       "      <td>100</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>-22.783143</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>0.991286</td>\n",
       "      <td>9.177143e-01</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>0.204157</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>2015.777778</td>\n",
       "      <td>61.428571</td>\n",
       "      <td>5.862007e+04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers majority_artist_genres              name    owner  \\\n",
       "0   18129916                    pop  Today's Top Hits  spotify   \n",
       "3    3787551              indie r&b          Are & Be  spotify   \n",
       "5    4254642   contemporary country       Hot Country  spotify   \n",
       "6    6639722                  latin     Â¡Viva Latino!  spotify   \n",
       "9    3323766                  focus    Peaceful Piano  spotify   \n",
       "\n",
       "                                           track_ids  num_tracks  \\\n",
       "0  ['0tBbt8CrmxbjRP0pueQkyU', ' 2amzBJRBPOGszBem4...          50   \n",
       "3  ['6gU9OKjOE7ghfEd55oRO57', ' 25wStx3LyTjYmHTd3...          51   \n",
       "5  ['54EWDYWhs4w6SODnxabuoh', ' 7rdK9NSJIRBZAiXC0...          51   \n",
       "6  ['2hl6q70unbviGo3g1R7uFx', ' 2SmgFAhQkQCQPyBiB...          50   \n",
       "9  ['1JoAjYaI3zvhXVx41HH7Fc', ' 7ih16mauHrpUMOIeW...         100   \n",
       "\n",
       "   avg_song_popularity  avg_loudness  avg_speechiness  avg_acousticness  \\\n",
       "0            84.277778     -5.696467         0.085307          0.170962   \n",
       "3            62.090909     -8.381700         0.118980          0.299180   \n",
       "5            77.200000     -6.154000         0.054200          0.199580   \n",
       "6            83.222222     -4.502375         0.084313          0.151738   \n",
       "9            58.000000    -22.783143         0.035443          0.991286   \n",
       "\n",
       "   avg_instrumentalness  avg_liveness  avg_valence  avg_num_artists  \\\n",
       "0          2.145467e-05      0.154687     0.326580         1.833333   \n",
       "3          7.865653e-02      0.111130     0.306480         1.090909   \n",
       "5          4.080000e-07      0.175000     0.536000         1.400000   \n",
       "6          1.028625e-05      0.120575     0.614750         2.222222   \n",
       "9          9.177143e-01      0.098943     0.204157         1.071429   \n",
       "\n",
       "   avg_num_markets  majority_explicit  majority_mode  avg_album_popularity  \\\n",
       "0        38.500000                0.0            0.0             81.444444   \n",
       "3        34.818182                0.0            1.0             59.727273   \n",
       "5        50.200000                0.0            1.0             73.400000   \n",
       "6        48.333333                0.0            1.0             80.333333   \n",
       "9        41.500000                0.0            0.0             51.333333   \n",
       "\n",
       "   avg_album_release_year  avg_artist_popularity  avg_artist_followers  \\\n",
       "0             2017.000000              91.160000          2.545533e+06   \n",
       "3             2016.818182              75.200000          1.603455e+06   \n",
       "5             2016.400000              78.857143          9.805109e+05   \n",
       "6             2017.000000              94.142857          2.632650e+06   \n",
       "9             2015.777778              61.428571          5.862007e+04   \n",
       "\n",
       "   majority_album_type_album  majority_album_type_compilation  \\\n",
       "0                          0                                0   \n",
       "3                          0                                0   \n",
       "5                          0                                0   \n",
       "6                          0                                0   \n",
       "9                          1                                0   \n",
       "\n",
       "   majority_album_type_single  \n",
       "0                           1  \n",
       "3                           1  \n",
       "5                           1  \n",
       "6                           1  \n",
       "9                           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(df)) < 0.75\n",
    "data_train = df[msk]\n",
    "data_test = df[~msk]\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_headers = list(data_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get variables\n",
    "X_train = data_train.iloc[:,5:]\n",
    "y_train = data_train.iloc[:,0]\n",
    "\n",
    "X_test = data_test.iloc[:,5:]\n",
    "y_test = data_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Linear Regression: 0.168225035255 0.181277116647\n"
     ]
    }
   ],
   "source": [
    "X_train2 = sm.add_constant(X_train.values)\n",
    "model = sm.OLS(y_train.values, X_train2)\n",
    "results = model.fit()\n",
    "\n",
    "y_hat_train = results.predict(X_train2)\n",
    "\n",
    "# test case\n",
    "X_test2 = sm.add_constant(X_test.values)\n",
    "y_hat_test = results.predict(X_test2)\n",
    "\n",
    "r2_score_train = r2_score(y_train, y_hat_train) \n",
    "r2_score_test = r2_score(y_test, y_hat_test)\n",
    "\n",
    "print('R^2 Values for Train, Test Using Linear Regression:', r2_score_train, r2_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Terms Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Polynomial Regression: [0.21866516189664709] [0.18486578914356244]\n"
     ]
    }
   ],
   "source": [
    "r2_train_poly = []\n",
    "r2_test_poly = []\n",
    "\n",
    "# make dataframes to add polynomial terms to\n",
    "cont = ['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_num_artists', 'avg_num_markets']\n",
    "X_binary_only = X_train.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_test_bin_only = X_test.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_poly = X_binary_only.copy()\n",
    "X_test_poly = X_test_bin_only.copy()\n",
    "\n",
    "X_poly_test_all = X_test.copy()\n",
    "X_poly_train_all = X_train.copy()\n",
    "\n",
    "# function to create and add polynomial terms to dataframe\n",
    "def add_poly_features(train, test, poly_train, poly_test, polylist):\n",
    "    for col in polylist:\n",
    "        for i in range(2,4):\n",
    "            poly_train[col + '_' + str(i)] = train[col]**i\n",
    "            poly_test[col + '_' + str(i)] = test[col]**i\n",
    "\n",
    "add_poly_features(X_train, X_test, X_poly_train_all, X_poly_test_all,cont)\n",
    "\n",
    "# polynomial term regression \n",
    "poly_regression_model = linear_model.LinearRegression(fit_intercept=False)\n",
    "poly_regression_model.fit(X_poly_train_all, y_train)\n",
    "\n",
    "y_hat_train = poly_regression_model.predict(X_poly_train_all)\n",
    "y_hat_test = poly_regression_model.predict(X_poly_test_all)\n",
    "\n",
    "\n",
    "r2_train_poly.append( r2_score(y_train, y_hat_train))\n",
    "r2_test_poly.append( r2_score(y_test, y_hat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Polynomial Regression:', r2_train_poly, r2_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using kNN Regression: [0.99999999826605368, 0.67361557405130701, 0.26014861730618322, 0.14666628473394638, 0.12441822659635149, 0.042620591885406456, 0.029105850221909146, 0.022963572284714795, 0.013139851669411118, 0.011592111214729361, 0.0092869321588529008, 0.0077948862622220227, 0.0073745784743184384, 0.0056233810101773418]\n",
      "\n",
      "R^2 Values for Test Using kNN Regression: [-0.75715473073802242, -0.25301680053630093, -0.30348630520483377, -0.094250067982748709, -0.12328060001080909, -0.021899414008623497, -0.013522963401996657, 0.0045474078918134042, 0.0031360746980091392, 0.0017065831673064302, 0.0013485495695024774, 0.0014863803700982947, 0.00016419258602440312, -0.00075057625934760175]\n"
     ]
    }
   ],
   "source": [
    "# try multiple k's\n",
    "K = [1, 2, 4,8, 10, 50, 100, 250, 500, 600, 700, 800, 900, 1000]\n",
    "r2_test_knn = []\n",
    "r2_train_knn = []\n",
    "\n",
    "# try each different k and calculate R^2\n",
    "for i,k in enumerate(K): \n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    predicted_pickups_train = knn_model.predict(X_train)\n",
    "    predicted_pickups = knn_model.predict(X_test)\n",
    "\n",
    "    r2_train_knn.append( r2_score(y_train, predicted_pickups_train))\n",
    "    r2_test_knn.append( r2_score(y_test, predicted_pickups))\n",
    "    \n",
    "print('R^2 Values for Train Using kNN Regression:', r2_train_knn)\n",
    "print()\n",
    "print('R^2 Values for Test Using kNN Regression:', r2_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.49720296756434346, 0.61270131485010926, 0.68781757760996243, 0.66572656890709236, 0.72579428734652485, 0.76220222715670116, 0.83028968917612855, 0.89600687647170285, 0.82751658981528342, 0.90397467822481714, 0.82688300968743556, 0.80932068679634084, 0.80088932016355352, 0.8318520139901675, 0.84760169764201365, 0.87436773242829824, 0.9327280066845034, 0.86419104646927214, 0.93431964941287748]\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.065688530132135381, 0.11686894621887656, 0.24313162668286292, 0.28709485521131284, 0.2662607744323261, 0.34904452912818174, 0.29851039695836878, 0.3065957790310373, 0.36954388468561639, 0.2522709301908852, 0.23787368602781456, 0.26886389619395945, 0.24574812074392371, 0.33606857579939109, 0.25281436758556375, 0.27813440591777383, 0.33600838787033338, 0.26840161712604982, 0.27994817289037111]\n"
     ]
    }
   ],
   "source": [
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "# check multiple depths to see which depth is best\n",
    "for i in range(1, 20):\n",
    "    rf_reg = RandomForestRegressor(max_depth=i)\n",
    "    rf_reg.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf_reg.predict(X_train)\n",
    "    rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "    r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf.append( r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf)\n",
    "print()\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth for Random Forest Tree Depth: 9\n"
     ]
    }
   ],
   "source": [
    "# get best depth\n",
    "index, value = max(enumerate(r2_test_rf), key=operator.itemgetter(1))\n",
    "best_depth = index + 1\n",
    "\n",
    "print('Best Depth for Random Forest Tree Depth:', best_depth )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge and Lasso for Polynomial Term Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge train R^2:  0.311660608922\n",
      "Ridge test R^2 0.26309415895\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression on Polynomial Term Regression\n",
    "lambdas = [.001,.005,1,5,10,50,100,500,1000]    \n",
    "ridge = RidgeCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "ridge.fit(X_poly_train_all, y_train)\n",
    "\n",
    "print(\"Ridge train R^2: \", ridge.score(X_poly_train_all, y_train))\n",
    "print('Ridge test R^2', ridge.score(X_poly_test_all, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilychen1/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso train R^2:  0.309383380859\n",
      "Lasso test R^2 0.26803387052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilychen1/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression on Polynomial Term Regression\n",
    "lasso = LassoCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "lasso.fit(X_poly_train_all, y_train)\n",
    "\n",
    "print(\"Lasso train R^2: \", lasso.score(X_poly_train_all, y_train))\n",
    "print('Lasso test R^2', lasso.score(X_poly_test_all, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Random Forest Regression: [0.8958707740469255] [0.29070087056355209]\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning Random Forest: Initial Run with max_depth set to the optimal depth from shotgun approach\n",
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "rf_reg = RandomForestRegressor(max_depth=best_depth)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "rf_yhat_train = rf_reg.predict(X_train)\n",
    "rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "r2_test_rf.append( r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Random Forest Regression:', r2_train_rf, r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.56797482287807854, 0.80234289053068186, 0.77059992272949063, 0.70152777008931655, 0.90530980473216849, 0.85275109969795582, 0.88201649617753375, 0.85743292898819212]\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.07571505945058421, 0.10618906817465157, 0.14651476417606069, 0.32637513644207894, 0.27808610681013535, 0.33125284656270726, 0.26565927221011654, 0.2952721502433362]\n"
     ]
    }
   ],
   "source": [
    "# step 1: fine tune the number of trees\n",
    "r2_train_rf_trees = []\n",
    "r2_test_rf_trees = []\n",
    "\n",
    "# create list of tree numbers we will test\n",
    "trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "\n",
    "# test the tree numbers keeping max_depth at 9\n",
    "for n_trees in trees:\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees, max_depth=best_depth, max_features='auto')\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_trees.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_trees.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_trees)\n",
    "print()\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Number of Trees: 32\n",
      "R^2 Value: 0.331252846563\n"
     ]
    }
   ],
   "source": [
    "# get best number of trees\n",
    "index, value = max(enumerate(r2_test_rf_trees), key=operator.itemgetter(1))\n",
    "best_tree = trees[index]\n",
    "\n",
    "print('Random Forest Best Number of Trees:',best_tree)\n",
    "print('R^2 Value:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.82566611110852284, 0.77028153913388597, 0.81294981310663916, 0.82230984221503411, 0.86399928188978148, 0.84900428685973228, 0.86796979785964978, 0.86999862619729362, 0.8765343315962304, 0.83978169521855706, 0.88528359486999786, 0.87353484950923743, 0.82726533523158174, 0.85297023789094073, 0.89051363502830783, 0.88520795662651808, 0.85059256851215825, 0.86209711928116417]\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.15794790583084561, 0.19010823363449014, 0.21701001115604357, 0.32057835078781416, 0.2695549598488991, 0.29352389205363116, 0.23822094648134462, 0.22518511833625854, 0.26129543627494345, 0.26912500788228744, 0.28568486755867872, 0.28869981484340268, 0.29008893080067877, 0.28629686174585578, 0.26584568328217706, 0.27836093527718631, 0.28419643148861906, 0.27408654680703304]\n"
     ]
    }
   ],
   "source": [
    "# step 2: fine tune the number of predictors used\n",
    "r2_train_rf_feat = []\n",
    "r2_test_rf_feat = []\n",
    "\n",
    "# 19 = len(list(X_train)) is the maximum number of predictors we have\n",
    "for i in range(1, len(list(X_train))):\n",
    "    rf = RandomForestRegressor(n_estimators=32, max_depth=9, max_features=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_feat.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_feat.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_feat)\n",
    "print()\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Number of Predictors for Best Value: 4\n",
      "Best R^2 Value Using Only Spotify Predictors: 0.320578350788\n"
     ]
    }
   ],
   "source": [
    "# get best number of predictors\n",
    "index, value = max(enumerate(r2_test_rf_feat), key=operator.itemgetter(1))\n",
    "\n",
    "print('Random Forest Number of Predictors for Best Value:',index+1)\n",
    "print('Best R^2 Value Using Only Spotify Predictors:',value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read csv that combines previous csv from spotify with few additional columns of additional predictors\n",
    "df = pd.read_csv('final_dataset.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop(['Unnamed: 0'], 1)\n",
    "df = pd.get_dummies(df, columns=['majority_key','majority_time_signature','majority_album_type'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers</th>\n",
       "      <th>majority_artist_genres</th>\n",
       "      <th>name</th>\n",
       "      <th>owner</th>\n",
       "      <th>track_ids</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>avg_song_popularity</th>\n",
       "      <th>avg_danceability</th>\n",
       "      <th>avg_energy</th>\n",
       "      <th>avg_loudness</th>\n",
       "      <th>avg_speechiness</th>\n",
       "      <th>avg_acousticness</th>\n",
       "      <th>avg_instrumentalness</th>\n",
       "      <th>avg_liveness</th>\n",
       "      <th>avg_valence</th>\n",
       "      <th>avg_duration_ms</th>\n",
       "      <th>avg_num_artists</th>\n",
       "      <th>avg_num_markets</th>\n",
       "      <th>majority_explicit</th>\n",
       "      <th>majority_mode</th>\n",
       "      <th>avg_album_popularity</th>\n",
       "      <th>avg_album_release_year</th>\n",
       "      <th>avg_artist_popularity</th>\n",
       "      <th>avg_artist_followers</th>\n",
       "      <th>majority_key_0.0</th>\n",
       "      <th>majority_key_1.0</th>\n",
       "      <th>majority_key_2.0</th>\n",
       "      <th>majority_key_3.0</th>\n",
       "      <th>majority_key_4.0</th>\n",
       "      <th>majority_key_5.0</th>\n",
       "      <th>majority_key_6.0</th>\n",
       "      <th>majority_key_7.0</th>\n",
       "      <th>majority_key_8.0</th>\n",
       "      <th>majority_key_9.0</th>\n",
       "      <th>majority_key_10.0</th>\n",
       "      <th>majority_key_11.0</th>\n",
       "      <th>majority_time_signature_0.0</th>\n",
       "      <th>majority_time_signature_1.0</th>\n",
       "      <th>majority_time_signature_3.0</th>\n",
       "      <th>majority_time_signature_4.0</th>\n",
       "      <th>majority_album_type_album</th>\n",
       "      <th>majority_album_type_compilation</th>\n",
       "      <th>majority_album_type_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18129916</td>\n",
       "      <td>pop</td>\n",
       "      <td>Today's Top Hits</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['0tBbt8CrmxbjRP0pueQkyU', ' 2amzBJRBPOGszBem4...</td>\n",
       "      <td>50</td>\n",
       "      <td>84.277778</td>\n",
       "      <td>0.624333</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>-5.696467</td>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.170962</td>\n",
       "      <td>2.145467e-05</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>0.326580</td>\n",
       "      <td>202240.933333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.444444</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>91.160000</td>\n",
       "      <td>2.545533e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3787551</td>\n",
       "      <td>indie r&amp;b</td>\n",
       "      <td>Are &amp; Be</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['6gU9OKjOE7ghfEd55oRO57', ' 25wStx3LyTjYmHTd3...</td>\n",
       "      <td>51</td>\n",
       "      <td>62.090909</td>\n",
       "      <td>0.643800</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>-8.381700</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>0.299180</td>\n",
       "      <td>7.865653e-02</td>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.306480</td>\n",
       "      <td>235682.800000</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>34.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.727273</td>\n",
       "      <td>2016.818182</td>\n",
       "      <td>75.200000</td>\n",
       "      <td>1.603455e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4254642</td>\n",
       "      <td>contemporary country</td>\n",
       "      <td>Hot Country</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['54EWDYWhs4w6SODnxabuoh', ' 7rdK9NSJIRBZAiXC0...</td>\n",
       "      <td>51</td>\n",
       "      <td>77.200000</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>-6.154000</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.199580</td>\n",
       "      <td>4.080000e-07</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>198442.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>50.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.400000</td>\n",
       "      <td>2016.400000</td>\n",
       "      <td>78.857143</td>\n",
       "      <td>9.805109e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6639722</td>\n",
       "      <td>latin</td>\n",
       "      <td>Â¡Viva Latino!</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['2hl6q70unbviGo3g1R7uFx', ' 2SmgFAhQkQCQPyBiB...</td>\n",
       "      <td>50</td>\n",
       "      <td>83.222222</td>\n",
       "      <td>0.726625</td>\n",
       "      <td>0.783375</td>\n",
       "      <td>-4.502375</td>\n",
       "      <td>0.084313</td>\n",
       "      <td>0.151738</td>\n",
       "      <td>1.028625e-05</td>\n",
       "      <td>0.120575</td>\n",
       "      <td>0.614750</td>\n",
       "      <td>207268.125000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>94.142857</td>\n",
       "      <td>2.632650e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3323766</td>\n",
       "      <td>focus</td>\n",
       "      <td>Peaceful Piano</td>\n",
       "      <td>spotify</td>\n",
       "      <td>['1JoAjYaI3zvhXVx41HH7Fc', ' 7ih16mauHrpUMOIeW...</td>\n",
       "      <td>100</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.082329</td>\n",
       "      <td>-22.783143</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>0.991286</td>\n",
       "      <td>9.177143e-01</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>0.204157</td>\n",
       "      <td>171100.857143</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>2015.777778</td>\n",
       "      <td>61.428571</td>\n",
       "      <td>5.862007e+04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers majority_artist_genres              name    owner  \\\n",
       "0   18129916                    pop  Today's Top Hits  spotify   \n",
       "3    3787551              indie r&b          Are & Be  spotify   \n",
       "5    4254642   contemporary country       Hot Country  spotify   \n",
       "6    6639722                  latin     Â¡Viva Latino!  spotify   \n",
       "9    3323766                  focus    Peaceful Piano  spotify   \n",
       "\n",
       "                                           track_ids  num_tracks  \\\n",
       "0  ['0tBbt8CrmxbjRP0pueQkyU', ' 2amzBJRBPOGszBem4...          50   \n",
       "3  ['6gU9OKjOE7ghfEd55oRO57', ' 25wStx3LyTjYmHTd3...          51   \n",
       "5  ['54EWDYWhs4w6SODnxabuoh', ' 7rdK9NSJIRBZAiXC0...          51   \n",
       "6  ['2hl6q70unbviGo3g1R7uFx', ' 2SmgFAhQkQCQPyBiB...          50   \n",
       "9  ['1JoAjYaI3zvhXVx41HH7Fc', ' 7ih16mauHrpUMOIeW...         100   \n",
       "\n",
       "   avg_song_popularity  avg_danceability  avg_energy  avg_loudness  \\\n",
       "0            84.277778          0.624333    0.660000     -5.696467   \n",
       "3            62.090909          0.643800    0.454000     -8.381700   \n",
       "5            77.200000          0.574000    0.686200     -6.154000   \n",
       "6            83.222222          0.726625    0.783375     -4.502375   \n",
       "9            58.000000          0.381714    0.082329    -22.783143   \n",
       "\n",
       "   avg_speechiness  avg_acousticness  avg_instrumentalness  avg_liveness  \\\n",
       "0         0.085307          0.170962          2.145467e-05      0.154687   \n",
       "3         0.118980          0.299180          7.865653e-02      0.111130   \n",
       "5         0.054200          0.199580          4.080000e-07      0.175000   \n",
       "6         0.084313          0.151738          1.028625e-05      0.120575   \n",
       "9         0.035443          0.991286          9.177143e-01      0.098943   \n",
       "\n",
       "   avg_valence  avg_duration_ms  avg_num_artists  avg_num_markets  \\\n",
       "0     0.326580    202240.933333         1.833333        38.500000   \n",
       "3     0.306480    235682.800000         1.090909        34.818182   \n",
       "5     0.536000    198442.000000         1.400000        50.200000   \n",
       "6     0.614750    207268.125000         2.222222        48.333333   \n",
       "9     0.204157    171100.857143         1.071429        41.500000   \n",
       "\n",
       "   majority_explicit  majority_mode  avg_album_popularity  \\\n",
       "0                0.0            0.0             81.444444   \n",
       "3                0.0            1.0             59.727273   \n",
       "5                0.0            1.0             73.400000   \n",
       "6                0.0            1.0             80.333333   \n",
       "9                0.0            0.0             51.333333   \n",
       "\n",
       "   avg_album_release_year  avg_artist_popularity  avg_artist_followers  \\\n",
       "0             2017.000000              91.160000          2.545533e+06   \n",
       "3             2016.818182              75.200000          1.603455e+06   \n",
       "5             2016.400000              78.857143          9.805109e+05   \n",
       "6             2017.000000              94.142857          2.632650e+06   \n",
       "9             2015.777778              61.428571          5.862007e+04   \n",
       "\n",
       "   majority_key_0.0  majority_key_1.0  majority_key_2.0  majority_key_3.0  \\\n",
       "0                 0                 0                 0                 0   \n",
       "3                 0                 0                 1                 0   \n",
       "5                 0                 0                 1                 0   \n",
       "6                 0                 1                 0                 0   \n",
       "9                 1                 0                 0                 0   \n",
       "\n",
       "   majority_key_4.0  majority_key_5.0  majority_key_6.0  majority_key_7.0  \\\n",
       "0                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "5                 0                 0                 0                 0   \n",
       "6                 0                 0                 0                 0   \n",
       "9                 0                 0                 0                 0   \n",
       "\n",
       "   majority_key_8.0  majority_key_9.0  majority_key_10.0  majority_key_11.0  \\\n",
       "0                 0                 0                  0                  1   \n",
       "3                 0                 0                  0                  0   \n",
       "5                 0                 0                  0                  0   \n",
       "6                 0                 0                  0                  0   \n",
       "9                 0                 0                  0                  0   \n",
       "\n",
       "   majority_time_signature_0.0  majority_time_signature_1.0  \\\n",
       "0                            0                            0   \n",
       "3                            0                            0   \n",
       "5                            0                            0   \n",
       "6                            0                            0   \n",
       "9                            0                            0   \n",
       "\n",
       "   majority_time_signature_3.0  majority_time_signature_4.0  \\\n",
       "0                            0                            1   \n",
       "3                            0                            1   \n",
       "5                            0                            1   \n",
       "6                            0                            1   \n",
       "9                            0                            1   \n",
       "\n",
       "   majority_album_type_album  majority_album_type_compilation  \\\n",
       "0                          0                                0   \n",
       "3                          0                                0   \n",
       "5                          0                                0   \n",
       "6                          0                                0   \n",
       "9                          1                                0   \n",
       "\n",
       "   majority_album_type_single  \n",
       "0                           1  \n",
       "3                           1  \n",
       "5                           1  \n",
       "6                           1  \n",
       "9                           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(df)) < 0.75\n",
    "data_train = df[msk]\n",
    "data_test = df[~msk]\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictor list\n",
    "column_headers = list(data_train.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shotgun Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get variables\n",
    "X_train = data_train.iloc[:,5:]\n",
    "y_train = data_train.iloc[:,0]\n",
    "\n",
    "X_test = data_test.iloc[:,5:]\n",
    "y_test = data_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Linear Regression: 0.188062242633 0.127995346803\n"
     ]
    }
   ],
   "source": [
    "X_train2 = sm.add_constant(X_train.values)\n",
    "model = sm.OLS(y_train.values, X_train2)\n",
    "results = model.fit()\n",
    "\n",
    "y_hat_train = results.predict(X_train2)\n",
    "\n",
    "# test case\n",
    "X_test2 = sm.add_constant(X_test.values)\n",
    "y_hat_test = results.predict(X_test2)\n",
    "\n",
    "r2_score_train = r2_score(y_train, y_hat_train) \n",
    "r2_score_test = r2_score(y_test, y_hat_test)\n",
    "\n",
    "print('R^2 Values for Train, Test Using Linear Regression:', r2_score_train, r2_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Terms Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Polynomial Regression: [0.22365592656318156] [0.19078809329451474]\n"
     ]
    }
   ],
   "source": [
    "r2_train_poly = []\n",
    "r2_test_poly = []\n",
    "\n",
    "# set up dataframe to add polynomial terms to\n",
    "cont = ['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_danceability', 'avg_energy', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_duration_ms', 'avg_num_artists', 'avg_num_markets']\n",
    "X_binary_only = X_train.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_danceability', 'avg_energy', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_duration_ms', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_test_bin_only = X_test.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_danceability', 'avg_energy', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_duration_ms', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_poly = X_binary_only.copy()\n",
    "X_test_poly = X_test_bin_only.copy()\n",
    "\n",
    "X_poly_test_all = X_test.copy()\n",
    "X_poly_train_all = X_train.copy()\n",
    "\n",
    "# function to create and add polynomial terms to dataframe\n",
    "def add_poly_features(train, test, poly_train, poly_test, polylist):\n",
    "    for col in polylist:\n",
    "        for i in range(2,4):\n",
    "            poly_train[col + '_' + str(i)] = train[col]**i\n",
    "            poly_test[col + '_' + str(i)] = test[col]**i\n",
    "\n",
    "add_poly_features(X_train, X_test, X_poly_train_all, X_poly_test_all,cont)\n",
    "\n",
    "# regress and calculate R^2\n",
    "poly_regression_model = linear_model.LinearRegression(fit_intercept=False)\n",
    "poly_regression_model.fit(X_poly_train_all, y_train)\n",
    "\n",
    "y_hat_train = poly_regression_model.predict(X_poly_train_all)\n",
    "y_hat_test = poly_regression_model.predict(X_poly_test_all)\n",
    "\n",
    "r2_train_poly.append( r2_score(y_train, y_hat_train))\n",
    "r2_test_poly.append( r2_score(y_test, y_hat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Polynomial Regression:', r2_train_poly, r2_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using KNN Regression: [0.99999999826605368, 0.70705295578349214, 0.26384447277586165, 0.14062785261746957, 0.16815399746437676, 0.041790871252071704, 0.026784122297934254, 0.022334620712726183, 0.013199508562418361, 0.011615787116215581, 0.0092690893153853926, 0.0079270698554815278, 0.0074171109814979985, 0.0056618388771036976]\n",
      "\n",
      "R^2 Values for Test Using KNN Regression: [-0.87195646189656983, -0.32627859453665375, -0.1542926908927027, -0.089021508792754611, -0.11809935938908334, -0.020776306046869086, -0.010578038605963069, 0.0031685923025387419, 0.0036867169843481928, 0.0026448150105176094, 0.0015801451321187931, 0.0015217888123526535, 0.00056359830487651141, -0.0006410793680169391]\n"
     ]
    }
   ],
   "source": [
    "# test different k's\n",
    "K = [1, 2, 4,8, 10, 50, 100, 250, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "r2_test_knn = []\n",
    "r2_train_knn = []\n",
    "\n",
    "# test different k's and regress\n",
    "for i,k in enumerate(K): \n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    predicted_pickups_train = knn_model.predict(X_train)\n",
    "    predicted_pickups = knn_model.predict(X_test)\n",
    "\n",
    "    r2_train_knn.append( r2_score(y_train, predicted_pickups_train))\n",
    "    r2_test_knn.append( r2_score(y_test, predicted_pickups))\n",
    "    \n",
    "print('R^2 Values for Train Using KNN Regression:', r2_train_knn)\n",
    "print()\n",
    "print('R^2 Values for Test Using KNN Regression:', r2_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.49720296756434346, 0.61053350899380598, 0.68024242103697308, 0.67417419454609795, 0.72703450561074345, 0.76129438982654363, 0.82826168965869496, 0.89075878029084954, 0.82731366848664911, 0.90645817073650103, 0.82926781510319325, 0.79301657823217642, 0.78252458746760933, 0.79662562095222622, 0.84607245407198439, 0.86602676866652106, 0.92853095764601801, 0.83285277634645305, 0.9345492041547051]\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.065688530132135381, 0.11955126119857296, 0.23689289946392322, 0.26770594423792349, 0.26822437144144051, 0.30804616302553378, 0.29194690047452032, 0.30943028691050356, 0.36153466389056399, 0.30359581277335412, 0.22811542159418852, 0.24413334080333959, 0.17365091726726267, 0.2942474156517787, 0.23550012470930493, 0.25922089750101251, 0.24252559131939444, 0.26024406499389796, 0.25732779460683675]\n"
     ]
    }
   ],
   "source": [
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "# check multiple depths to see which depth is best\n",
    "for i in range(1, 20):\n",
    "    rf_reg = RandomForestRegressor(max_depth=i)\n",
    "    rf_reg.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf_reg.predict(X_train)\n",
    "    rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "    r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf.append( r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf)\n",
    "print()\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth for Random Forest Tree Depth: 9\n"
     ]
    }
   ],
   "source": [
    "# get best depth\n",
    "index, value = max(enumerate(r2_test_rf), key=operator.itemgetter(1))\n",
    "best_depth2 = index + 1\n",
    "\n",
    "print('Best Depth for Random Forest Tree Depth:', best_depth2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge and Lasso on Polynomial Term Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge train R^2:  0.326717798114\n",
      "Ridge test R^2 0.256967193697\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression on Polynomial Term Regression\n",
    "lambdas = [.001,.005,1,5,10,50,100,500,1000]    \n",
    "ridge = RidgeCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "ridge.fit(X_poly_train_all, y_train)\n",
    "\n",
    "print(\"Ridge train R^2: \", ridge.score(X_poly_train_all, y_train))\n",
    "print('Ridge test R^2', ridge.score(X_poly_test_all, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilychen1/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso train R^2:  0.330738827492\n",
      "Lasso test R^2 0.222855946887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilychen1/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression on Polynomial Term Regression\n",
    "lasso = LassoCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "lasso.fit(X_poly_train_all, y_train)\n",
    "\n",
    "print(\"Lasso train R^2: \", lasso.score(X_poly_train_all, y_train))\n",
    "print('Lasso test R^2', lasso.score(X_poly_test_all, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Random Forest Regression: [0.90262541883850489] [0.24087108131907387]\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning Random Forest: get R^2 values for optimal depth that we calculated in shotgun approach\n",
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "rf_reg = RandomForestRegressor(max_depth=best_depth2)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "rf_yhat_train = rf_reg.predict(X_train)\n",
    "rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "r2_test_rf.append(r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Random Forest Regression:', r2_train_rf, r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.57492208179960747, 0.79613269275111742, 0.74639675519356485, 0.70857324665172727, 0.90271868614388662, 0.85278439937628614, 0.88376628817650682, 0.85892059438543478]\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [-0.019096793332201933, 0.063317838578937025, 0.1650974481859171, 0.28993793816624602, 0.25554733422998355, 0.30215898703465505, 0.26622004029166813, 0.2695700261496573]\n"
     ]
    }
   ],
   "source": [
    "# step 1: fine tuning number of trees\n",
    "r2_train_rf_trees = []\n",
    "r2_test_rf_trees = []\n",
    "\n",
    "# will try various number of trees\n",
    "trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "\n",
    "# try different trees with optimal depth\n",
    "for n_trees in trees:\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees, max_depth=best_depth2, max_features='auto')\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_trees.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_trees.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_trees)\n",
    "print()\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Number of Trees: 32\n",
      "R^2 Value: 0.302158987035\n"
     ]
    }
   ],
   "source": [
    "# get best number of trees\n",
    "index, value = max(enumerate(r2_test_rf_trees), key=operator.itemgetter(1))\n",
    "best_trees2 = trees[index]\n",
    "\n",
    "print('Random Forest Best Number of Trees:',best_trees2)\n",
    "print('R^2 Value:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.75633988113401796, 0.70946280665336514, 0.74961922274263015, 0.79715576473639183, 0.85743741826413333, 0.83103940853478919, 0.88522452216497172, 0.85777386983596993, 0.88534598066540782, 0.84321293307864076, 0.88287446763216326, 0.87535793526961547, 0.81132008668654254, 0.84070341093556755, 0.90326674743422597, 0.87555445691910205, 0.85607681263792534, 0.84174249333054441, 0.86104110520470523, 0.84989793225520183, 0.86331742273837153, 0.86374805813696498, 0.91830319188432075, 0.87902292764811663, 0.81898358578364983, 0.81512189037245752, 0.88782640132252211, 0.85056039360514102, 0.85254321536783029, 0.85774173971159018, 0.78129295743555305, 0.8484575148908714, 0.8238652173578408, 0.89008544896313146, 0.90070565416255888, 0.87816773093967326, 0.8643900597449834]\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.13685407984731046, 0.13056892014350696, 0.20169352611776525, 0.17519220035219507, 0.17637356446846342, 0.19977953355757672, 0.19916545541152464, 0.19710749640464198, 0.24704056223281323, 0.20284096428194665, 0.23951639299763949, 0.28502083413380452, 0.1718507125250972, 0.24473154530435814, 0.25582648336544878, 0.26182614979885499, 0.21486595984387513, 0.26392864716334097, 0.27670487697996038, 0.26839906679688541, 0.22897224146566386, 0.21466243502811977, 0.25629771936123813, 0.25013958498328981, 0.23611616488848763, 0.29951831281468189, 0.24439258739783642, 0.28019120208068038, 0.25150094389644284, 0.28236049961817022, 0.25970156426833924, 0.2782170560177093, 0.28385026953194825, 0.23285751371026409, 0.24946118929459549, 0.26824313258624244, 0.25621452521169175]\n"
     ]
    }
   ],
   "source": [
    "# step 2: fine tuning number of predictors used\n",
    "r2_train_rf_feat = []\n",
    "r2_test_rf_feat = []\n",
    "\n",
    "# 38 = len(list(X_train)) is the maximum number of predictors we have\n",
    "for i in range(1, len(list(X_train))):\n",
    "    rf = RandomForestRegressor(n_estimators=best_trees2, max_depth=best_depth2, max_features=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_feat.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_feat.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_feat)\n",
    "print()\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Number of Predictors for Best Value: 26\n",
      "Final Best R^2 Value: 0.299518312815\n"
     ]
    }
   ],
   "source": [
    "# get best number of predictors and best R^2 value\n",
    "index, value = max(enumerate(r2_test_rf_feat), key=operator.itemgetter(1))\n",
    "\n",
    "print('RandomForest Number of Predictors for Best Value:',index+1)\n",
    "print('Final Best R^2 Value:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
